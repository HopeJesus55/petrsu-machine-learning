{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Стекинг.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Стекинг**"
      ],
      "metadata": {
        "id": "_pjZUNkmP7DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стекинг – алгоритм ансамблирования, основные отличия которого от беггинга, случайного леса и бустинга состоят в следующем:\n",
        "\n",
        "- он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия\n",
        "- результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения)\n",
        "\n",
        "Обучение стекинга проходит в несколько этапов:\n",
        "1. общая выборка разделяется на тренировочную и тестовую\n",
        "\n",
        "2. тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются (n−1) фолдов для обучения базовых алгоритмов и один – для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались\n",
        "\n",
        "Самым простым примером стекинга является блендинг. Блендинг представляет из себя \"мета-алгоритм\", предсказание которого строится как взвешенная сумма базовых алгоритмов."
      ],
      "metadata": {
        "id": "SXgBPTFcSxWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Постановка задачи**\n",
        "\n",
        "Применить блендинг для бустинга и линейной регрессии.\n"
      ],
      "metadata": {
        "id": "mfCyWBJRP_aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Описание структуры исходных данных**"
      ],
      "metadata": {
        "id": "oJBzftJKQziF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Описание используемых функций и их параметров**\n",
        "\n",
        "pandas.DataFrame(data=None, columns=None) - создает дата фрейм\n",
        "\n",
        ">- data - двумерный массив с данными.\n",
        ">- columns - название столбцов.\n",
        "\n",
        "sklearn.model_selection.train_test_split(arrays1, arrays2, test_size=None, random_state=None, stratify=None)\n",
        "\n",
        ">- arrays1 - образец набора функций для разделения.\n",
        ">- arrays2 - образец результата, который нужно разделить.\n",
        ">- test_size - доля выборок, если это целое число, это количество выборок.\n",
        ">- random_state - это начальное число случайного числа.\n",
        "\n",
        "def rmse(y_true, y_pred) - функция рассчитывающая среднеквадратичную ошибку(расстояние между двумя точками)\n",
        "\n",
        ">- y_true - 1 точка\n",
        ">- y_pred - 2 точка\n",
        "\n",
        "StandardScaler() - создаёт объект функции StandardScaler()\n",
        "\n",
        "object.fit_transform(data) - преобразует данные таким образом, что его распределение будет иметь среднее значение 0 и стандартное отклонение 1\n",
        "\n",
        ">- data - двумерный массив с данными.\n",
        "\n",
        "object.fit_transform(data) - Стандартизирует данные\n",
        "\n",
        ">- data - двумерный массив с данными.\n",
        "\n",
        "def select_weights(y_true, y_pred_1, y_pred_2) - функция, которая находит взвешенную сумму базовых алгоритмов."
      ],
      "metadata": {
        "id": "k5addKcCQ4WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение задачи**"
      ],
      "metadata": {
        "id": "GO0Xgw9HQ6Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#!pip install catboost\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Загружаем набор данных\n",
        "data = fetch_california_housing()\n",
        "\n",
        "# Считываем DataFrame \n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Делим на обучающие и тестовые\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "\n",
        "# функция расчета среднеквадратичной ошибки\n",
        "def rmse(y_true, y_pred):\n",
        "    error = (y_true - y_pred) ** 2\n",
        "    return np.sqrt(np.mean(error))\n",
        "\n",
        "# Инициализация модели\n",
        "cbm = CatBoostRegressor(iterations=100, max_depth=4, learning_rate=0.01, loss_function='RMSE', logging_level='Silent')\n",
        "# Обучение модели\n",
        "cbm.fit(X_train, y_train)\n",
        "\n",
        "# Рассчет точности\n",
        "y_pred_cbm = cbm.predict(X_test)\n",
        "y_train_pred_cbm = cbm.predict(X_train)\n",
        "\n",
        "# Масштабирование данных\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Инициализация модели\n",
        "lr = LinearRegression()\n",
        "# Обучение модели\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "# Рассчет точности\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "y_train_pred_lr = lr.predict(X_train_scaled)\n",
        "\n",
        "def select_weights(y_true, y_pred_1, y_pred_2):\n",
        "    grid = np.linspace(0, 1, 1000)\n",
        "    metric = []\n",
        "    for w_0 in grid:\n",
        "        w_1 = 1 - w_0\n",
        "        y_a = w_0 * y_pred_1 + w_1 * y_pred_2\n",
        "        metric.append([rmse(y_true, y_a), w_0, w_1])\n",
        "    return metric\n",
        "  \n",
        "min(select_weights(y_train, y_train_pred_cbm, y_train_pred_lr), key=lambda x: x[0])\n",
        "rmse_blending_train, w_0, w_1 = min(select_weights(y_train, y_train_pred_cbm, y_train_pred_lr), key=lambda x: x[0])\n",
        "print(rmse_blending_train)\n",
        "rmse(y_test, y_pred_cbm * w_0 +  y_pred_lr * w_1)\n",
        "print(rmse(y_test, y_pred_cbm * w_0 +  y_pred_lr * w_1))\n",
        "\n"
      ],
      "metadata": {
        "id": "b37-ENu0jMCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6947aec5-b5c5-4e1c-fed7-c0d7ecec2edb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE GB = 0.8162\n",
            "Test RMSE GB = 0.8272\n",
            "Train RMSE LR = 0.7168\n",
            "Test RMSE LR = 0.7443\n",
            "0.7053105051555533\n",
            "0.7255682914828336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Визуализация результата по возможности**"
      ],
      "metadata": {
        "id": "ZLjFtHc-RBYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train RMSE GB = %.4f\" % rmse(y_train, y_train_pred_cbm))\n",
        "print(\"Test RMSE GB = %.4f\" % rmse(y_test, y_pred_cbm))\n",
        "print(\"Train RMSE LR = %.4f\" % rmse(y_train, y_train_pred_lr))\n",
        "print(\"Test RMSE LR = %.4f\" % rmse(y_test, y_pred_lr))\n",
        "print(\"Train RMSE BL = %.4f\" % rmse_blending_train)\n",
        "print(\"Test RMSE BL = %.4f\" % rmse(y_test, y_pred_cbm * w_0 +  y_pred_lr * w_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCcsmAvt-bxV",
        "outputId": "20dfd7bc-5b0e-4f05-e3b3-8e7c9e7b8c3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE GB = 0.8162\n",
            "Test RMSE GB = 0.8272\n",
            "Train RMSE LR = 0.7168\n",
            "Test RMSE LR = 0.7443\n",
            "Train RMSE BL = 0.7053\n",
            "Test RMSE BL = 0.7256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Интерпретация результата**\n",
        "\n",
        "В итоге получаем качество на тестовой выборке лучше, чем у каждого алгоритма в отдельности."
      ],
      "metadata": {
        "id": "Z66qfPu9RFoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задания для самостоятельной работы**\n",
        "\n",
        "1. Применить блендинг для логистической и линейной регрессии.\n",
        "2. Применить блендинг для логистической регрессии и бустинга."
      ],
      "metadata": {
        "id": "7iOFeU78RMKy"
      }
    }
  ]
}